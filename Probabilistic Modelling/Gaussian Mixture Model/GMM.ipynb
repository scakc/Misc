{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPMI : Implementing Spherical Gaussian Mixture Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from IPython.display import clear_output as clr\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.cluster import KMeans as KM\n",
    "import matplotlib as mpl\n",
    "mpl.rc('image', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing data\n",
    "mat = scipy.io.loadmat('mnist_small.mat')\n",
    "X = mat[\"X\"]\n",
    "y = mat[\"Y\"]\n",
    "print(\"Input shape\", X.shape, \", Label shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the GMM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Class of GMM Model\n",
    "class GMM_spherical:\n",
    "    '''\n",
    "    ||========================================================= Model GMM ==========================================================||\n",
    "    ||___________________________________________________Developed by Abhishek Kumar________________________________________________||\n",
    "    ||______________________________________________________________________________________________________________________________||\n",
    "    \n",
    "    This is Spherical GMM Model with both batch and stepwise EM algorithm implemented as fit and partial_fit for function respectively.\n",
    "    '''\n",
    "    def __init__(self, n_components = 10, max_iter = 200):\n",
    "        \n",
    "        self.n_components = n_components\n",
    "        self.means = None\n",
    "        self.vars = None\n",
    "        self.pis = None\n",
    "        self.max_iter = max_iter\n",
    "        self.idls = [] # Incomplete data log likelihoods\n",
    "        self.nums = []\n",
    "    \n",
    "    def InitVars(self, D):\n",
    "        self.pis = np.ones((self.n_components,1))/self.n_components\n",
    "        self.means = np.random.rand(self.n_components, D)\n",
    "        self.vars = np.array([1])\n",
    "        \n",
    "    def E_step(self, X):\n",
    "        '''\n",
    "        X : N x D\n",
    "        '''\n",
    "        N, D = X.shape\n",
    "        gamma = np.zeros((X.shape[0], self.n_components))\n",
    "        for j in range(self.n_components):\n",
    "            \n",
    "            delta = X-self.means[j,:] # NxD \n",
    "            expo = -0.5*(np.sum(delta**2, axis = 1))/(self.vars)\n",
    "            gamma[:,j] = expo+np.log(self.pis[j])-(D/2)*np.log(2*np.pi*self.vars)\n",
    "        \n",
    "        gamma = np.exp((gamma-gamma.max(axis = 1).reshape(-1,1)))\n",
    "        gamma = gamma/np.sum(gamma, axis = 1).reshape(-1,1)\n",
    "        \n",
    "        return gamma\n",
    "    \n",
    "    def M_step(self, X, gammas):\n",
    "        '''\n",
    "        X : NxD\n",
    "        gammas : NxK\n",
    "        '''\n",
    "        N, D = X.shape\n",
    "        K = gammas.shape[1]\n",
    "        Nms = np.sum(gammas, axis = 0).reshape(K,1) # Kx1\n",
    "        \n",
    "        #pi\n",
    "        self.pis = Nms/N\n",
    "        # mu\n",
    "        numerator = np.dot(gammas.T, X) # KxD\n",
    "        self.means = numerator/Nms\n",
    "        # var\n",
    "        prod = np.zeros((N,K))\n",
    "        for j in range(K):\n",
    "            delta = X - self.means[j,:] # NxD\n",
    "            vec = np.sum(delta**2, axis = 1) # Nx1\n",
    "            prod[:,j] = vec\n",
    "        \n",
    "        prod = prod*gammas\n",
    "        self.vars = np.sum(prod)/(N*D)\n",
    "        \n",
    "    def get_idl(self, X):\n",
    "        N, D = X.shape\n",
    "        X_max = X.max()\n",
    "        likhd = 0\n",
    "        gamma = np.zeros((N, self.n_components))\n",
    "        for j in range(self.n_components):    \n",
    "            delta = X-self.means[j,:] # NxD \n",
    "            expo = -0.5*(np.sum(delta**2, axis = 1))/(self.vars)\n",
    "            gamma[:,j] = expo+np.log(self.pis[j])-(D/2)*np.log(2*np.pi*self.vars)\n",
    "            \n",
    "        gammas = self.E_step(X)\n",
    "        mul = np.sum(gammas*gamma)\n",
    "        \n",
    "        return mul\n",
    "    \n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        This is Batch EM version\n",
    "        '''\n",
    "        N, D = X.shape\n",
    "        self.InitVars(D)\n",
    "        old_idl = self.get_idl(X)\n",
    "        new_idl = old_idl + 100\n",
    "        for i in range(self.max_iter):\n",
    "            gammas = self.E_step(X)\n",
    "            self.M_step(X, gammas)\n",
    "            new_idl = self.get_idl(X)\n",
    "            print(new_idl)\n",
    "            clr(wait = True)\n",
    "            self.idls.append(new_idl)\n",
    "            self.nums.append(i*N)\n",
    "            diff = abs(new_idl - old_idl)\n",
    "            if(diff < 1):\n",
    "                break\n",
    "            old_idl = new_idl+0.000001\n",
    "            \n",
    "        return self.nums, self.idls \n",
    "    \n",
    "    def partial_fit(self, X, batch_size = 100, kr = 0.55, init_me = True, km_init = False):\n",
    "        '''\n",
    "        This is the stepwise EM version\n",
    "        '''\n",
    "        N, D = X.shape\n",
    "        if(init_me):\n",
    "            self.InitVars(D)\n",
    "            if(km_init):\n",
    "                kmmodel = KM(n_clusters = self.n_components)\n",
    "                kmmodel.fit(X)\n",
    "                self.means = kmmodel.cluster_centers_\n",
    "        else:\n",
    "            assert(self.means.shape[1] == D)\n",
    "\n",
    "        old_idl = -999\n",
    "        new_idl = old_idl + 100\n",
    "        old_idl_mini = 0\n",
    "        new_idl_mini = old_idl_mini + 100\n",
    "        diff = 1000    \n",
    "        np.random.shuffle(X)\n",
    "        old_lrate = 0\n",
    "        n_batches = (N//batch_size)\n",
    "        gammas = self.E_step(X)\n",
    "        self.M_step(X, gammas)\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            l_rate = ((i//n_batches)+1)**(-kr)\n",
    "            ul = i%batch_size\n",
    "            ll = min(ul+batch_size, X.shape[0])\n",
    "            mini_X = X[ul:ll,:]\n",
    "            if(mini_X.shape[0] == 0):\n",
    "                continue \n",
    "\n",
    "            pis = self.pis.copy()\n",
    "            mus = self.means.copy()\n",
    "            var = self.vars.copy()\n",
    "\n",
    "            gammas = self.E_step(mini_X)\n",
    "            self.M_step(mini_X, gammas)\n",
    "\n",
    "            self.pis = pis*(1-l_rate) + l_rate*(self.pis)\n",
    "            self.means = mus*(1-l_rate) + l_rate*(self.means)\n",
    "            self.vars = var*(1-l_rate) + l_rate*(self.vars)\n",
    "                \n",
    "            if(i%n_batches==0):\n",
    "                new_idl = self.get_idl(X)\n",
    "                print(new_idl, diff)\n",
    "                clr(wait = True)\n",
    "                self.idls.append(new_idl)\n",
    "                self.nums.append(i*batch_size)\n",
    "                diff = abs(new_idl - old_idl)\n",
    "                if(diff < 1):\n",
    "                    break\n",
    "                old_idl = new_idl+0.000001\n",
    "            \n",
    "            \n",
    "        return self.nums, self.idls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for running the model as EM, sEM, sEM with kmeans init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all(K, F, bsize  =2000):\n",
    "    \n",
    "    ##  Batch EM \n",
    "    model = GMM_spherical(n_components=K)\n",
    "    his_batch = model.fit(Xd)\n",
    "    fig, ax = plt.subplots(F,K//F, figsize = [K//F,F+1])\n",
    "    for i in range(K):\n",
    "        if(F==1):\n",
    "            ax[i//F].imshow((model.means[i]*stdX + meanX).reshape(28,28))\n",
    "        else: \n",
    "            ax[i%F][i//F].imshow((model.means[i]*stdX + meanX).reshape(28,28))\n",
    "    fig.suptitle(\"EM at K = \" + str(K))\n",
    "    plt.savefig(\"GMMbEM_\"+str(K)+\".png\")\n",
    "    plt.show()\n",
    "    \n",
    "    ## Stepwise EM (sEM)\n",
    "    model = GMM_spherical(n_components=K)\n",
    "    his_stepwise = model.partial_fit(Xd, batch_size = bsize, kr = 0.55, init_me = True, km_init = False)\n",
    "    fig, ax = plt.subplots(F,K//F, figsize = [K//F,F+1])\n",
    "    for i in range(K):\n",
    "        if(F == 1):\n",
    "            ax[i//F].imshow((model.means[i]*stdX + meanX).reshape(28,28))\n",
    "        else:    \n",
    "            ax[i%F][i//F].imshow((model.means[i]*stdX + meanX).reshape(28,28))\n",
    "    fig.suptitle(\"sEM at K = \" + str(K))\n",
    "    plt.savefig(\"GMMsEM_\"+str(K)+\".png\")\n",
    "    plt.show()\n",
    "    \n",
    "    ## Stepwise EM with Kmeans init (skEM)\n",
    "    model = GMM_spherical(n_components=K)\n",
    "    his_stepwise_km = model.partial_fit(Xd, batch_size = bsize, kr = 0.55, init_me = True, km_init = True)\n",
    "    fig, ax = plt.subplots(F,K//F, figsize = [K//F,F+1])\n",
    "    for i in range(K):\n",
    "        if(F==1):\n",
    "            ax[i//F].imshow((model.means[i]*stdX + meanX).reshape(28,28))\n",
    "        else:\n",
    "            ax[i%F][i//F].imshow((model.means[i]*stdX + meanX).reshape(28,28))\n",
    "    fig.suptitle(\"sEM at K = \" + str(K) + \"with Kmeans init\")\n",
    "    plt.savefig(\"GMMskEM_\"+str(K)+\".png\")\n",
    "    plt.show()\n",
    "    \n",
    "    '''\n",
    "    Comparing the log likelihoods ...............\n",
    "    '''\n",
    "    plt.plot(his_batch[0],his_batch[1], label  = \"EM\")\n",
    "    plt.plot(his_stepwise[0],his_stepwise[1], label  = \"sEM\")\n",
    "    plt.plot(his_stepwise_km[0],his_stepwise_km[1], label = \"sEM Kmean Init\")\n",
    "    plt.title(\"K = \"+str(K)+\" Likelihoods\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Compare\" + str(K)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data for numerical stabilitiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanX = X.mean()\n",
    "stdX = X.std()\n",
    "min_X = X.min()\n",
    "max_X = X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xd = (X - meanX)/stdX\n",
    "Xd = (X - min_X)/(max_X - min_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the GMM at different K values for Mnist data.\n",
    "\n",
    "Run all four cells below, This might take few minutes to run. I suggest you go drink a tea relax, then come back and look at the plots :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "F = K//5\n",
    "calc_all(K,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "F = K//5\n",
    "calc_all(K,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 15\n",
    "F = K//5\n",
    "calc_all(K,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20\n",
    "F = K//5\n",
    "calc_all(K,F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thankyou\n",
    "\n",
    "Abhishek Kumar\n",
    "\n",
    "18111002"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
