{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output as clr\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f1bba7115f8>"
      ]
     },
     "execution_count": 2371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if(torch.cuda.is_available()):\n",
    "    deivce = \"gpu\"\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1bbb261b38>"
      ]
     },
     "execution_count": 2372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Synthetic Data Genration\n",
    "\n",
    "'''Basis Generation'''\n",
    "k1 = np.zeros((6,6))\n",
    "k1[0:3,1] = 1.0\n",
    "k1[1,0:3] = 1.0\n",
    "\n",
    "k2 = np.zeros((6,6))\n",
    "k2[0:3,-3:] = 1.0\n",
    "k2[1,-2] = 0\n",
    "\n",
    "k3 = np.zeros((6,6))\n",
    "k3[-3:,0:3] = 1.0\n",
    "k3[-3:-1,2] = 0.0\n",
    "k3[-3,1:2] = 0.0\n",
    "\n",
    "k4 = np.zeros((6,6))\n",
    "k4[-3:,-2] = 1.0\n",
    "k4[-3,-3:] = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(1,4)\n",
    "\n",
    "ax[0].imshow(k1)\n",
    "ax[1].imshow(k2)\n",
    "ax[2].imshow(k3)\n",
    "ax[3].imshow(k4)\n",
    "\n",
    "\n",
    "'''Data Generation'''\n",
    "\n",
    "train_size = 3000\n",
    "test_size = 500\n",
    "\n",
    "train_weights = np.random.rand(train_size, 4)>0.5\n",
    "train_data = np.dot(train_weights,np.array([k1.reshape(-1,1),k2.reshape(-1,1),k3.reshape(-1,1),k4.reshape(-1,1)]).reshape(4,-1))\n",
    "# train_data += np.random.normal(0,0.01, size = train_data.shape)\n",
    "\n",
    "test_weights = np.random.rand(test_size, 4)>0.5\n",
    "test_data = np.dot(test_weights,np.array([k1.reshape(-1,1),k2.reshape(-1,1),k3.reshape(-1,1),k4.reshape(-1,1)]).reshape(4,-1))\n",
    "# test_data += np.random.normal(0,0.01, size = test_data.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,4)\n",
    "\n",
    "ax[0].imshow(train_data[0].reshape(6,6))\n",
    "ax[1].imshow(train_data[300].reshape(6,6))\n",
    "ax[2].imshow(test_data[0].reshape(6,6))\n",
    "ax[3].imshow(test_data[300].reshape(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data.reshape(-1,1,6,6), batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images(images):\n",
    "    images = torchvision.utils.make_grid(images)\n",
    "    show_image(images[0])\n",
    "\n",
    "def show_image(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images = dataiter.next()\n",
    "show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3090,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLM_NP(nn.Module):\n",
    "    def __init__(self, latent_variable_dim, alpha = 1.0, rholr = 10e-12):\n",
    "        super(GLM_NP, self).__init__()\n",
    "        \n",
    "        ### Global Params\n",
    "        self.eps1 = torch.tensor(10e-6).float()\n",
    "        self.eps2 = torch.tensor(10e-4).float()\n",
    "        \n",
    "        # V : Stick breaking : Beta {kumaraswamy}\n",
    "        self.aeys = nn.Parameter(torch.rand(1,latent_variable_dim) + 2)\n",
    "        self.bees = nn.Parameter(torch.rand(1,latent_variable_dim) + 2)\n",
    "        self.unif_sampler = torch.distributions.uniform.Uniform(0, 1)\n",
    "        \n",
    "        # IBP prior\n",
    "        self.alpha = alpha\n",
    "        self.euler_constant = np.e\n",
    "        \n",
    "        # Z : Bernoulli\n",
    "        self.phi = nn.Parameter(torch.randn((36 + 1),latent_variable_dim))\n",
    "        \n",
    "        # Gumbel Softmax params\n",
    "        self.temperature = 10\n",
    "        self.gumbel_sampler = torch.distributions.gumbel.Gumbel(0,1)\n",
    "        \n",
    "        # Basis\n",
    "        self.A = nn.Parameter(torch.randn(latent_variable_dim, 36))\n",
    "        \n",
    "        ### Russian Roulette part\n",
    "        self.rhos = torch.zeros(latent_variable_dim + 1,1) + 0.5\n",
    "        self.rholr = rholr\n",
    "        \n",
    "    \n",
    "    def reparameterize_gumbel_kumaraswamy(self, inter_z, p):\n",
    "        '''Proper Sampling is required with masking'''\n",
    "        \n",
    "        N, K = inter_z.shape\n",
    "        \n",
    "        U = self.unif_sampler.sample([N,K]) + self.eps1\n",
    "        G0 = self.gumbel_sampler.sample([N,K])\n",
    "        G1 = self.gumbel_sampler.sample([N,K])\n",
    "        \n",
    "#         logV = (-(U.log()/self.bees.view(1,K)).exp()).log1p()/self.aeys.view(1,K)\n",
    "        V = (1-U.pow(1/self.aeys[:,:K])).pow(1/self.bees[:,:K])\n",
    "        \n",
    "        pi = torch.zeros_like(V)+1\n",
    "        for i in range(K):\n",
    "            for j in range(i+1):\n",
    "                pi[:,i] *= V[:,j]\n",
    "        \n",
    "        pi += self.eps2\n",
    "        rand_num = torch.rand_like(pi)\n",
    "        rand_logit = (rand_num/(1-rand_num)).log()\n",
    "        \n",
    "        \n",
    "        logit_pi = (pi/(1-pi)).log()\n",
    "        alpha = (logit_pi + inter_z + rand_logit).sigmoid().pow(0.98)\n",
    "        \n",
    "        z1 = ((alpha + self.eps1).log() + G1)/self.temperature\n",
    "        z0 = ((1 - alpha + self.eps1).log() + G0)/self.temperature\n",
    "        \n",
    "        maxz = torch.max(z0,z1)\n",
    "        z1 = z1 - maxz\n",
    "        z0 = z0 - maxz\n",
    "        \n",
    "        logsumexp = (z1.exp() + z0.exp()).log()\n",
    "        \n",
    "        z1 = z1 - logsumexp + self.eps1\n",
    "        z0 = z0 - logsumexp + self.eps1\n",
    "        \n",
    "        y = z1.exp()/(z0.exp() + z1.exp())\n",
    "        \n",
    "#         if(p != 0):\n",
    "#             mask = torch.rand_like(y)*0\n",
    "#             mask[:,:p] = 1\n",
    "#         else:\n",
    "#             mask = 1\n",
    "        \n",
    "#         y = y*mask\n",
    "        \n",
    "        return y, alpha, pi\n",
    "        \n",
    "    def forward(self, input, k):\n",
    "        x = input.view(-1, 36)\n",
    "        N, D = x.shape\n",
    "        \n",
    "#         if(k != 0 and False):\n",
    "#             mask2 = torch.rand_like(self.phi)*0\n",
    "#             mask2[:,:k] = 1\n",
    "#         else:\n",
    "#             mask2 = 1\n",
    "            \n",
    "        \n",
    "        inter_z = self.phi # 785 x K\n",
    "        x_cat = torch.cat((input.view(N,36), torch.ones(N).view(N,-1)), 1).view(N,36+1) # N x 785\n",
    "        inter_z = torch.mm(x_cat, inter_z[:,:k]) # N x K\n",
    "        \n",
    "        z, gi, pi = self.reparameterize_gumbel_kumaraswamy(inter_z, k) # N x K\n",
    "#         print(z.shape)\n",
    "#         assert 1== 2\n",
    "        x = self.decode(z, k)\n",
    "        \n",
    "        return x, z, gi, pi\n",
    "\n",
    "    \n",
    "    def decode(self, z, k):\n",
    "#         if(k != 0):\n",
    "#             mask = torch.rand_like(self.A)*0\n",
    "#             mask[:,:k] = 1\n",
    "#         else:\n",
    "#             mask = 1\n",
    "        x = F.linear(z, self.A.transpose(0,1)[:,:k]).sigmoid()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def add_k_node(self, k):\n",
    "        # Add k latent features ...\n",
    "        if(k == 0):\n",
    "            return \n",
    "        with torch.no_grad():\n",
    "            self.aeys = nn.Parameter(torch.cat((self.aeys, torch.rand(1,k) + 2), 1))\n",
    "            self.bees = nn.Parameter(torch.cat((self.bees, torch.rand(1,k) + 2), 1))\n",
    "            \n",
    "            self.phi = nn.Parameter(torch.cat((self.phi, torch.randn((36 + 1),k)), 1))\n",
    "            self.A = nn.Parameter(torch.cat((self.A, torch.randn(k, 36)), 0))\n",
    "            \n",
    "            \n",
    "            self.rhos = torch.cat((self.rhos, torch.zeros(k,1) + 0.5), 0)\n",
    "    \n",
    "    def del_k_node(self, k):\n",
    "        # Retain k Latent Features ...\n",
    "        if(k == 0 or k == self.get_current_K()):\n",
    "            return\n",
    "        with torch.no_grad():\n",
    "            c_K = self.get_current_K()\n",
    "            \n",
    "            self.aeys = nn.Parameter(list(torch.split(self.aeys, c_K - k , 1))[0])\n",
    "            self.bees = nn.Parameter(list(torch.split(self.bees, c_K - k , 1))[0])\n",
    "            \n",
    "            self.phi = nn.Parameter(list(torch.split(self.phi, c_K - k , 1))[0])\n",
    "            self.A = nn.Parameter(list(torch.split(self.A, c_K - k , 0))[0])\n",
    "            \n",
    "            self.rhos = list(torch.split(self.rhos, c_K - k + 1, 0))[0]\n",
    "                             \n",
    "    def get_current_K(self):\n",
    "        return self.aeys.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3098,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kth_trunc_loss(model, images, K = 0):\n",
    "    \n",
    "    recon_image, z, gi, pi = model(images, K)\n",
    "    softplus = nn.Softplus()\n",
    "    eps = model.eps1\n",
    "    if(K == 0):\n",
    "        K = model.aeys.shape[1]\n",
    "    \n",
    "    z = z[:,:K]\n",
    "    pi = pi[:,:K]\n",
    "    gi = gi[:,:K]\n",
    "    \n",
    "    \n",
    "    KL_kuma = ((model.aeys - model.alpha)/(model.aeys))*(-model.euler_constant -torch.digamma(model.bees) - 1/model.bees)\n",
    "    KL_kuma += (model.aeys.log() + model.bees.log())\n",
    "    KL_kuma += -(model.bees - 1)/(model.bees)\n",
    "    \n",
    "#     print(KL_kuma)\n",
    "    KL_kuma = torch.sum(KL_kuma[:,:K])\\\n",
    "    \n",
    "    logit_pi = (pi+eps).log() - (1-pi+eps).log()\n",
    "    logit_x  =  (z+eps).log() - (1 -z+eps).log()\n",
    "    logit_gi = (gi+eps).log() - (1-gi+eps).log()\n",
    "    \n",
    "    \n",
    "\n",
    "    exp_term_p = logit_pi - logit_x*(model.temperature+1-1)\n",
    "    exp_term_q = logit_gi - logit_x*(model.temperature+1-1)\n",
    "    log_tau = torch.log(torch.tensor(model.temperature, requires_grad = False))\n",
    "    \n",
    "    \n",
    "#     print(exp_term_p[0], exp_term_q[0])\n",
    "    \n",
    "    \n",
    "    tau = model.temperature\n",
    "    \n",
    "#     log_pz = log_tau + exp_term_p - 2.0*((pi/z.pow(tau) + (1-pi)/((1-z).pow(tau))).log())\n",
    "#     log_qz = log_tau + exp_term_q - 2.0*((gi/z.pow(tau) + (1-gi)/((1-z).pow(tau))).log())\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    log_pz = log_tau + exp_term_p - 2.0*softplus(exp_term_p)\n",
    "    log_qz = log_tau + exp_term_q - 2.0*softplus(exp_term_q)\n",
    "\n",
    "#     print(log_qz[0,:], log_pz[0,:])\n",
    "\n",
    "\n",
    "    \n",
    "    Kt = torch.argmax(torch.arange(K)*(z[:,:K].sum(dim = 0) > 0).long()) + 1\n",
    "    \n",
    "    mask_K = torch.zeros_like(log_pz)\n",
    "    mask_K[:,:K] = 1\n",
    "    \n",
    "    mask_Kt = torch.zeros_like(log_qz)\n",
    "    mask_Kt[:,:Kt] = 1\n",
    "    \n",
    "    log_pz = (mask_K*log_pz)[log_pz == log_pz]\n",
    "    log_qz = (mask_Kt*log_qz)[log_qz == log_qz]\n",
    "\n",
    "    \n",
    "    KL_gumb = log_qz.sum(dim = 0) - log_pz.sum(dim = 0)\n",
    "    \n",
    "    KL_gumb = KL_gumb[KL_gumb == KL_gumb]\n",
    "#     print(KL_gumb)\n",
    "    KL_gumb = torch.sum(KL_gumb)\n",
    "    \n",
    "    \n",
    "    ''' Add some more KL terms from K||B ,  '''\n",
    "    \n",
    "    Lik = -0.5*(recon_image - images.view(-1,36)).pow(2)\n",
    "#     print(Lik[0])\n",
    "    Lik = torch.sum(Lik) - float(36*0.5*np.log(2*np.pi))\n",
    "#     Lik = -F.binary_cross_entropy(recon_image, images.view(-1, 36), reduction='sum')\n",
    "    \n",
    "    KL_l = KL_kuma + KL_gumb\n",
    "#     print(KL_kuma, KL_gumb)\n",
    "    \n",
    "#     \n",
    "#     assert(1==2)\n",
    "    return -Lik  + KL_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_k_nodes(model , new_K = 0):\n",
    "    \n",
    "    current_K = model.get_current_K()\n",
    "    if(current_K < new_K):\n",
    "        model.add_k_node(new_K - current_K)\n",
    "    elif(current_K > new_K):\n",
    "        model.del_k_node(current_K - new_K)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.01)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrs_loss(model, images, curr_K):\n",
    "    \n",
    "    l = torch.zeros(curr_K,1)\n",
    "    for i in range(curr_K):\n",
    "        l[i,:] = get_kth_trunc_loss(model, images, K = i+1)\n",
    "        \n",
    "    \n",
    "    one_minus_rho = (1 - model.rhos[1:curr_K+2]).view(curr_K,1)\n",
    "    \n",
    "    return l, one_minus_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, images, add_max = 5, sample = False):\n",
    "    \n",
    "    \"\"\" sample a trucation level and then do the same\"\"\"\n",
    "    \n",
    "    curr_K = model.get_current_K()\n",
    "    model.rhos[0] = 1\n",
    "    \n",
    "    optimizer = retain_k_nodes(model , new_K = curr_K + add_max)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(sample):\n",
    "        optimizer = retain_k_nodes(model , new_K = curr_K + add_max)\n",
    "\n",
    "        curr_K = model.get_current_K()\n",
    "        # Sample a truncation level\n",
    "        m_k = torch.zeros_like(model.rhos[:curr_K,:])\n",
    "        for i in range(curr_K):\n",
    "            prod = 1\n",
    "            for j in range(i+1):\n",
    "                prod*=model.rhos[j,:]\n",
    "\n",
    "            m_k[i,:] = (1-model.rhos[i+1])*prod\n",
    "            \n",
    "        m_k /= m_k.sum()\n",
    "\n",
    "        new_values = np.random.choice(np.arange(curr_K)+1,size = 5, p = m_k.view(1,-1).numpy()[0])\n",
    "        new_value = int(np.max(new_values))\n",
    "\n",
    "\n",
    "        optimizer = retain_k_nodes(model , new_K = new_value)\n",
    "        \n",
    "    else:\n",
    "        new_value = curr_K\n",
    "        optimizer = retain_k_nodes(model , new_K = new_value)\n",
    "    \n",
    "\n",
    "    print(\"Current Truncated Level :\", new_value)\n",
    "    print(model.rhos)\n",
    "    optimizer.zero_grad()\n",
    "    curr_K = model.get_current_K()\n",
    "    \n",
    "    \n",
    "    l ,one_minus_rho = rrs_loss(model, images, curr_K)\n",
    "    l_final_params = (l*one_minus_rho).sum()\n",
    "    \n",
    "    \n",
    "    ws = torch.zeros(curr_K+1, curr_K)\n",
    "    \n",
    "    for k in range(1,curr_K+1):\n",
    "        for i in range(curr_K):\n",
    "            if(i < k-1):\n",
    "                ws[k,i] = 0\n",
    "            elif(i == k-1):\n",
    "                ws[k,i] = 1/(model.rhos[k] - 1)\n",
    "            else:\n",
    "                ws[k,i] = 1/model.rhos[k]\n",
    "            \n",
    "    \n",
    "    rho_grads = (ws[1:,:]*(-l)*one_minus_rho).sum(dim = 1)/len(images)\n",
    "    \n",
    "    model.rhos[1:,:] = model.rhos[1:,:] + model.rholr*(rho_grads.view(-1,1))\n",
    "    \n",
    "    count_neg = 0\n",
    "    count_pos = 0\n",
    "    for i in range(curr_K+1):\n",
    "        if(model.rhos[i,0] < 0.):\n",
    "            model.rhos[i,0] = 0.\n",
    "            count_neg += 1\n",
    "        elif(model.rhos[i,0] > 1.0):\n",
    "            model.rhos[i,0] = 1.0\n",
    "            count_neg += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "#     model.rhos[-1] = 0.5\n",
    "    \n",
    "    model.rhos[model.rhos != model.rhos] = 0.5\n",
    "    \n",
    "    if(l_final_params != l_final_params):\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        l_final_params.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return l_final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3170,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = GLM_NP(2,4,10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3171,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "train_loss = []\n",
    "glm.temperature = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no : 2 batch_no : 5 curr_loss : 10.78033203125\n",
      "Current Truncated Level : 2\n",
      "tensor([[1.0000],\n",
      "        [0.4778],\n",
      "        [0.5000]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3172-3cbb14d64f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#         except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#             pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3169-9f8034872a97>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, images, add_max, sample)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mone_minus_rho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrrs_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0ml_final_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mone_minus_rho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3153-60c74ceda596>\u001b[0m in \u001b[0;36mrrs_loss\u001b[0;34m(model, images, curr_K)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kth_trunc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3098-89b8b20a6c54>\u001b[0m in \u001b[0;36mget_kth_trunc_loss\u001b[0;34m(model, images, K)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_kth_trunc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrecon_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msoftplus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3090-73bae5a84725>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, k)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0minter_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_z\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# N x K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize_gumbel_kumaraswamy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# N x K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;31m#         print(z.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m#         assert 1== 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3090-73bae5a84725>\u001b[0m in \u001b[0;36mreparameterize_gumbel_kumaraswamy\u001b[0;34m(self, inter_z, p)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mG1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mG0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mmaxz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 filename, lineno, name, lookup_line=False, locals=f_locals))\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# to our compiled codes can be produced.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ipython_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(glm.parameters(), 0.02)\n",
    "for epoch in range(50):\n",
    "    \n",
    "    glm.temperature /= 1.15\n",
    "    if(glm.temperature < .2):\n",
    "        glm.temperature = 0.2\n",
    "        \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images = data.float()\n",
    "        images = images.to(device)\n",
    "\n",
    "#         try:\n",
    "        if((i+1)%20 == 0 and True):\n",
    "            l = train_step(glm, images, 1, True)\n",
    "        else:\n",
    "            l = train_step(glm, images, 1, False)\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "        train_loss.append((l/((1 - glm.rhos[:-1]).sum())).item() / len(images))\n",
    "\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         l = get_kth_trunc_loss(glm, images, K = 0)\n",
    "#         try:\n",
    "#             l.backward()\n",
    "#         except:\n",
    "#             pass\n",
    "#         train_loss.append(l.item() / len(images))\n",
    "#         optimizer.step()\n",
    "    \n",
    "        \n",
    "\n",
    "        if(i%1 == 0):\n",
    "            clr(wait = True)\n",
    "            print(\"Epoch no :\", epoch + 1, \"batch_no :\", i, \"curr_loss :\",  train_loss[-1])\n",
    "        \n",
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = max(glm.get_current_K(),2)\n",
    "fig, ax = plt.subplots(1,K)\n",
    "for i in range(K):\n",
    "    ax[i].imshow(glm.A[i].view(6,6).detach(), cmap= 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2990,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.14943222714666"
      ]
     },
     "execution_count": 2990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2991,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[5.7499, 5.6096, 6.1618, 5.7039]], requires_grad=True)"
      ]
     },
     "execution_count": 2991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.aeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2992,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.5274, 0.3416, 0.8005, 1.1599]], requires_grad=True)"
      ]
     },
     "execution_count": 2992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.bees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2993,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.3821,  1.1238,  0.7847, -1.4641],\n",
       "        [ 0.2605,  1.9567,  0.2069,  0.7509],\n",
       "        [-1.1024, -0.4701, -0.5143, -0.1900],\n",
       "        [ 0.0173,  1.0820,  0.4549,  0.0194],\n",
       "        [ 0.1031,  0.6749, -0.4637, -0.0895],\n",
       "        [-1.5787, -1.4245, -1.5536,  0.5881],\n",
       "        [-1.1932, -0.4118,  1.4653,  1.2274],\n",
       "        [ 0.6780, -0.4260,  1.0764,  0.0155],\n",
       "        [ 0.3060,  0.5522, -1.9422, -0.7223],\n",
       "        [ 0.4024, -1.2349,  1.2416,  0.3861],\n",
       "        [ 0.7699, -0.9974,  0.3385, -1.5833],\n",
       "        [-0.7281,  0.8934, -0.2296, -0.0530],\n",
       "        [ 0.8702,  0.2973, -0.4277,  0.0283],\n",
       "        [-0.1177, -1.7772, -0.9530, -1.4104],\n",
       "        [-1.3297, -0.2237, -0.3231,  1.8877],\n",
       "        [ 0.4562, -0.9098,  0.1043,  0.1319],\n",
       "        [ 0.7284,  1.9070,  1.4384, -1.6160],\n",
       "        [ 0.4087, -0.8994, -1.1140,  0.5685],\n",
       "        [-1.6800, -0.0758,  0.6930,  1.5428],\n",
       "        [-0.7013,  1.3545,  1.5300,  1.6688],\n",
       "        [-1.9637, -1.8993, -0.8815,  2.1975],\n",
       "        [-1.4181,  0.1951,  0.6661,  0.4860],\n",
       "        [-1.1748,  0.0249,  1.0849, -0.3076],\n",
       "        [-0.2987,  0.0514, -1.3271,  0.0691],\n",
       "        [ 0.9595,  1.7592, -1.4731,  1.5050],\n",
       "        [ 0.4103, -0.4668,  1.7004, -1.7970],\n",
       "        [-1.8415, -0.9648,  0.4201, -0.3513],\n",
       "        [ 0.5270, -1.7887, -0.3441, -0.5584],\n",
       "        [ 0.7235, -0.6085, -0.4699,  0.5057],\n",
       "        [-0.1519, -0.2998, -0.6230,  0.8132],\n",
       "        [ 0.0071, -0.7160,  0.6629, -0.3517],\n",
       "        [-0.9146,  1.3496,  0.3831, -0.5600],\n",
       "        [ 1.1160, -1.9192, -1.9679, -0.4138],\n",
       "        [ 0.5874, -1.0477,  1.4177, -1.2887],\n",
       "        [ 2.1297,  0.4823, -0.1088, -0.8919],\n",
       "        [-0.4051,  2.1479, -1.1361,  1.1379],\n",
       "        [ 0.2497, -0.1510, -0.0686,  0.1703]], requires_grad=True)"
      ]
     },
     "execution_count": 2993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2994,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [0.8000],\n",
       "        [0.7500],\n",
       "        [0.6667],\n",
       "        [0.5000]])"
      ]
     },
     "execution_count": 2994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.rhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2995,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
